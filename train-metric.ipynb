{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charming-plenty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch-metric-learning in /opt/conda/lib/python3.8/site-packages (1.6.2)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-metric-learning) (1.8.0a0+52ea372)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from pytorch-metric-learning) (1.19.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.8/site-packages (from pytorch-metric-learning) (1.0.2)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.8/site-packages (from pytorch-metric-learning) (0.9.0a0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from pytorch-metric-learning) (4.53.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.6.0->pytorch-metric-learning) (3.7.4.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning) (1.6.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn->pytorch-metric-learning) (2.1.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /opt/conda/lib/python3.8/site-packages (from torchvision->pytorch-metric-learning) (9.2.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install pytorch-metric-learning\n",
    "! pip install MulticoreTSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "from torch import optim\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from MulticoreTSNE import MulticoreTSNE as TSNE\n",
    "from pytorch_metric_learning.miners import TripletMarginMiner\n",
    "from pytorch_metric_learning.distances import CosineSimilarity\n",
    "from pytorch_metric_learning.losses import TripletMarginLoss\n",
    "from pytorch_metric_learning.reducers import ThresholdReducer\n",
    "from pytorch_metric_learning import losses, testers\n",
    "\n",
    "from PIL import Image\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coastal-copper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def args():\n",
    "    def str2bool(v):\n",
    "        if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
    "            return True\n",
    "        elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
    "            return False\n",
    "        else:\n",
    "            raise argparse.ArgumentTypeError('Unsupported value encountered.')\n",
    "    \n",
    "    #\n",
    "    parser.add_argument('--data_path', default='./dataset/', type=str, dest='data_path')\n",
    "    parser.add_argument('--exp', default=0, type=int, dest='exp')\n",
    "    parser.add_argument('--seed', default=42, type=int, dest='seed')\n",
    "    parser.add_argument('--debug', default=False, type=bool, dest='debug')\n",
    "    \n",
    "    parser.add_argument('--model_name', default='resnet34d', type=str, dest='model_name')\n",
    "    parser.add_argument('--loss_name', default=\"TripletMargin\", type=str, dest='loss_name')\n",
    "    parser.add_argument('--distance_name', default=\"CosineSimilarity\", type=str, dest='distance_name')\n",
    "\n",
    "    parser.add_argument('--epoch', default=20, type=int, dest='epoch')\n",
    "    parser.add_argument('--pretrained', default=True, type=bool, dest='pretrained')\n",
    "    parser.add_argument('--inp_channels', default=3, type=int, dest='inp_channels')\n",
    "    parser.add_argument('--batch_size', default=64, type=int, dest='batch_size')\n",
    "    parser.add_argument('--lr', default=1e-5, type=float, dest='lr')\n",
    "    parser.add_argument('--out_features', default=128, type=int, dest='out_features')\n",
    "    \n",
    "    \n",
    "    # python\n",
    "    #args = parser.parse_args()\n",
    "\n",
    "    # jupyter\n",
    "    args_parser = parser.parse_args(args=['--exp', '4',\n",
    "                                         '--loss_name', 'Contrastive',\n",
    "                                         '--inp_channels', '1',\n",
    "                                         #'--debug', 'True'\n",
    "                                         ])\n",
    "    return args_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "opening-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-pollution",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset():\n",
    "    transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "    train_dataset = datasets.FashionMNIST(CFG.data_path, train=True, download=False, transform=transform)\n",
    "    test_dataset = datasets.FashionMNIST(CFG.data_path, train=False, transform=transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-petite",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, CFG):\n",
    "        super().__init__()\n",
    "        self.backbone = timm.create_model(\n",
    "            model_name=CFG.model_name, pretrained=CFG.pretrained, num_classes=CFG.out_features, in_chans=CFG.inp_channels)\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x = self.backbone(x)\n",
    "        output = x\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, mining_func, device, dataloader, optimizer, epoch):\n",
    "    model.train() \n",
    "    for idx, (inputs, labels) in enumerate(dataloader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        if mining_func == None:\n",
    "            embeddings = model(inputs)\n",
    "            loss = loss_func(embeddings, labels)\n",
    "        else:\n",
    "            embeddings = model(inputs)\n",
    "            indices_tuple = mining_func(embeddings, labels)\n",
    "            loss = loss_func(embeddings, labels, indices_tuple)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if idx % 100 == 0:\n",
    "            print('Epoch {} Iteration {}: Loss = {}'.format(epoch, idx, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-alliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, device, epoch):\n",
    "    _predicted_metrics = []\n",
    "    _true_labels = []\n",
    "    with torch.no_grad():    \n",
    "        for i, (inputs,  labels) in enumerate(dataloader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            metric = model(inputs).detach().cpu().numpy()\n",
    "            metric = metric.reshape(metric.shape[0], metric.shape[1])\n",
    "            _predicted_metrics.append(metric)\n",
    "            _true_labels.append(labels.detach().cpu().numpy())\n",
    "    return np.concatenate(_predicted_metrics), np.concatenate(_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-calvin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne(epoch):\n",
    "    inf_model = CustomModel(CFG).to(CFG.device)\n",
    "    inf_model.load_state_dict(torch.load(OUTPUT_DIR + \"/\" + f'epoch{epoch}_model.pth'))\n",
    "    test_predicted_metrics, test_true_labels = test(inf_model, test_loader, CFG.device, epoch)\n",
    "    tSNE_metrics = TSNE(n_components=2, random_state=CFG.seed,n_jobs=4).fit_transform(test_predicted_metrics)\n",
    "\n",
    "    plt.scatter(tSNE_metrics[:, 0], tSNE_metrics[:, 1], c=test_true_labels)\n",
    "    plt.colorbar()\n",
    "    plt.xlim([-40,40])\n",
    "    plt.ylim([-40,40])\n",
    "    plt.title(f\"epoch{epoch}\")\n",
    "    plt.savefig(OUTPUT_DIR + \"/\" + f\"output_epoch{epoch}.jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gif():\n",
    "    pictures=[]\n",
    "    for i in range(1,CFG.epoch+1):\n",
    "        pic_name=OUTPUT_DIR + f\"output_epoch{i}.jpg\"\n",
    "        img = Image.open(pic_name)\n",
    "        pictures.append(img)\n",
    "    \n",
    "    pictures[0].save(OUTPUT_DIR + \"/\" + f'{CFG.loss_name}.gif',save_all=True, append_images=pictures[1:],\n",
    "    optimize=False, duration=500, loop=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    CFG = args()\n",
    "    \n",
    "    CFG.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    print(CFG.debug)\n",
    "    if CFG.debug:\n",
    "        CFG.epoch = 1\n",
    "    seed_everything(seed=CFG.seed)\n",
    "    \n",
    "    OUTPUT_DIR = './'+'ex'+str(CFG.exp)+'/'+ CFG.loss_name +'/'\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "        \n",
    "    train_loader, test_loader = dataset()\n",
    "    \n",
    "    \n",
    "    model = CustomModel(CFG).to(CFG.device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=CFG.lr)\n",
    "    \n",
    "    test_predicted_metrics = []\n",
    "    test_true_labels = []\n",
    "    model_loss = 0\n",
    "    best_model_loss = 100\n",
    "    \n",
    "    if CFG.distance_name == 'CosineSimilarity':\n",
    "        distance = CosineSimilarity()\n",
    "\n",
    "    if CFG.loss_name == 'TripletMargin':\n",
    "        reducer = ThresholdReducer(low = 0)\n",
    "        loss_func = TripletMarginLoss(margin=0.2, distance=distance, reducer=reducer)\n",
    "        mining_func = TripletMarginMiner(margin=0.2, distance=distance)\n",
    "        \n",
    "    elif CFG.loss_name == 'SubCenterArcFace':\n",
    "        loss_func = losses.SubCenterArcFaceLoss(num_classes=10, embedding_size=128,distance=distance,).to(CFG.device)\n",
    "    elif CFG.loss_name == 'CosFace':\n",
    "        loss_func = losses.CosFaceLoss(num_classes=10, embedding_size=128,distance=distance).to(CFG.device)\n",
    "    elif CFG.loss_name == 'ArcFace':\n",
    "        loss_func = losses.ArcFaceLoss(num_classes=10, embedding_size=128,distance=distance).to(CFG.device)\n",
    "    elif CFG.loss_name == 'Contrastive':\n",
    "        loss_func = losses.ContrastiveLoss(pos_margin=0, neg_margin=1,distance=distance).to(CFG.device)\n",
    "    elif CFG.loss_name == 'Circle':\n",
    "        loss_func = losses.CircleLoss(m=0.4, gamma=80,distance=distance).to(CFG.device)\n",
    "    \n",
    "    for epoch in range(1, CFG.epoch + 1):\n",
    "        print('Epoch {}/{}'.format(epoch, CFG.epoch))\n",
    "        print('-' * 10)\n",
    "        if CFG.loss_name == 'TripletMargin': \n",
    "            train(model, loss_func, mining_func, CFG.device, train_loader, optimizer, epoch)\n",
    "        else:\n",
    "            mining_func = None\n",
    "            train(model, loss_func, mining_func, CFG.device, train_loader, optimizer, epoch)\n",
    "            \n",
    "        torch.save(model.state_dict(),OUTPUT_DIR + \"/\" + f'epoch{epoch}_model.pth')\n",
    "        tsne(epoch)\n",
    "    \n",
    "    #create gif \n",
    "    create_gif()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
